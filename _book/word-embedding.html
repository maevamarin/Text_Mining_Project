<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 7 Word Embedding | Dicours Analysis</title>
  <meta name="description" content="Chapter 7 Word Embedding | Dicours Analysis" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 7 Word Embedding | Dicours Analysis" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 7 Word Embedding | Dicours Analysis" />
  
  
  

<meta name="author" content="EugÃ©nie Mathieu, Maeva Marin, Hadrien Renger, Wajma Nazim" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="topic-modelling.html"/>
<link rel="next" href="supervised-learning.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.2/htmlwidgets.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.16/datatables.js"></script>
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.20/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk-1.1.0.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.0.1/js/crosstalk.min.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Basic introduction</a></li>
<li class="chapter" data-level="2" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>2</b> Introduction</a><ul>
<li class="chapter" data-level="2.1" data-path="introduction.html"><a href="introduction.html#overview-and-motivation"><i class="fa fa-check"></i><b>2.1</b> Overview and Motivation</a></li>
<li class="chapter" data-level="2.2" data-path="introduction.html"><a href="introduction.html#data-loadind"><i class="fa fa-check"></i><b>2.2</b> Data loadind</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="eda.html"><a href="eda.html"><i class="fa fa-check"></i><b>3</b> EDA</a><ul>
<li class="chapter" data-level="3.1" data-path="eda.html"><a href="eda.html#data-acquisition"><i class="fa fa-check"></i><b>3.1</b> Data Acquisition</a><ul>
<li class="chapter" data-level="3.1.1" data-path="eda.html"><a href="eda.html#emmanuel-macron"><i class="fa fa-check"></i><b>3.1.1</b> Emmanuel Macron</a></li>
<li class="chapter" data-level="3.1.2" data-path="eda.html"><a href="eda.html#boris-johnson"><i class="fa fa-check"></i><b>3.1.2</b> Boris Johnson</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="eda.html"><a href="eda.html#tokenisation-lemmatization-cleaning"><i class="fa fa-check"></i><b>3.2</b> Tokenisation, Lemmatization &amp; Cleaning</a><ul>
<li class="chapter" data-level="3.2.1" data-path="eda.html"><a href="eda.html#emmanuel-macron-1"><i class="fa fa-check"></i><b>3.2.1</b> Emmanuel Macron</a></li>
<li class="chapter" data-level="3.2.2" data-path="eda.html"><a href="eda.html#boris-johnson-1"><i class="fa fa-check"></i><b>3.2.2</b> Boris Johnson</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="eda.html"><a href="eda.html#document-term-matrix-dtm"><i class="fa fa-check"></i><b>3.3</b> Document-Term Matrix DTM</a><ul>
<li class="chapter" data-level="3.3.1" data-path="eda.html"><a href="eda.html#table"><i class="fa fa-check"></i><b>3.3.1</b> Table</a></li>
<li class="chapter" data-level="3.3.2" data-path="eda.html"><a href="eda.html#most-frequent-words"><i class="fa fa-check"></i><b>3.3.2</b> Most frequent words</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="eda.html"><a href="eda.html#tf-idf"><i class="fa fa-check"></i><b>3.4</b> TF-IDF</a><ul>
<li class="chapter" data-level="3.4.1" data-path="eda.html"><a href="eda.html#emmanuel-macron-2"><i class="fa fa-check"></i><b>3.4.1</b> Emmanuel Macron</a></li>
<li class="chapter" data-level="3.4.2" data-path="eda.html"><a href="eda.html#boris-johnson-2"><i class="fa fa-check"></i><b>3.4.2</b> Boris Johnson</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="eda.html"><a href="eda.html#cloud-of-words"><i class="fa fa-check"></i><b>3.5</b> Cloud of Words</a><ul>
<li class="chapter" data-level="3.5.1" data-path="eda.html"><a href="eda.html#usind-dfm"><i class="fa fa-check"></i><b>3.5.1</b> Usind DFM</a></li>
<li class="chapter" data-level="3.5.2" data-path="eda.html"><a href="eda.html#using-tf-idf"><i class="fa fa-check"></i><b>3.5.2</b> Using TF-IDF</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="eda.html"><a href="eda.html#lexical-divesity-token-type-ratio-ttr"><i class="fa fa-check"></i><b>3.6</b> Lexical Divesity Token Type Ratio TTR</a><ul>
<li class="chapter" data-level="3.6.1" data-path="eda.html"><a href="eda.html#emmanuel-macron-3"><i class="fa fa-check"></i><b>3.6.1</b> Emmanuel Macron</a></li>
<li class="chapter" data-level="3.6.2" data-path="eda.html"><a href="eda.html#boris-johnson-3"><i class="fa fa-check"></i><b>3.6.2</b> Boris Johnson</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="eda.html"><a href="eda.html#zipfs-law"><i class="fa fa-check"></i><b>3.7</b> Zipf's Law</a><ul>
<li class="chapter" data-level="3.7.1" data-path="eda.html"><a href="eda.html#emmanuel-macron-4"><i class="fa fa-check"></i><b>3.7.1</b> Emmanuel Macron</a></li>
<li class="chapter" data-level="3.7.2" data-path="eda.html"><a href="eda.html#boris-johnson-4"><i class="fa fa-check"></i><b>3.7.2</b> Boris Johnson</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="eda.html"><a href="eda.html#yules-index"><i class="fa fa-check"></i><b>3.8</b> Yule's index</a><ul>
<li class="chapter" data-level="3.8.1" data-path="eda.html"><a href="eda.html#emmanuel-macron-5"><i class="fa fa-check"></i><b>3.8.1</b> Emmanuel Macron</a></li>
<li class="chapter" data-level="3.8.2" data-path="eda.html"><a href="eda.html#boris-johnson-5"><i class="fa fa-check"></i><b>3.8.2</b> Boris Johnson</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="eda.html"><a href="eda.html#mattr"><i class="fa fa-check"></i><b>3.9</b> MATTR</a><ul>
<li class="chapter" data-level="3.9.1" data-path="eda.html"><a href="eda.html#emmanuel-macron-6"><i class="fa fa-check"></i><b>3.9.1</b> Emmanuel Macron</a></li>
<li class="chapter" data-level="3.9.2" data-path="eda.html"><a href="eda.html#boris-johnson-6"><i class="fa fa-check"></i><b>3.9.2</b> Boris Johnson</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html"><i class="fa fa-check"></i><b>4</b> Sentiment Analysis</a><ul>
<li class="chapter" data-level="4.1" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html#analysis-with-the-nrc-library"><i class="fa fa-check"></i><b>4.1</b> Analysis with the &quot;nrc&quot; library</a></li>
<li class="chapter" data-level="4.2" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html#analysis-with-the-lsd2015-dictionnary"><i class="fa fa-check"></i><b>4.2</b> Analysis with the LSD2015 dictionnary</a></li>
<li class="chapter" data-level="4.3" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html#analysis-with-the-afinn-dictionnary"><i class="fa fa-check"></i><b>4.3</b> Analysis with the &quot;afinn&quot; dictionnary</a><ul>
<li class="chapter" data-level="4.3.1" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html#analysis-using-nrc-dictionnary-and-valence-shifters"><i class="fa fa-check"></i><b>4.3.1</b> Analysis using &quot;nrc&quot;&quot; dictionnary and valence shifters</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="similarities.html"><a href="similarities.html"><i class="fa fa-check"></i><b>5</b> Similarities</a><ul>
<li class="chapter" data-level="5.1" data-path="similarities.html"><a href="similarities.html#boris"><i class="fa fa-check"></i><b>5.1</b> Boris</a></li>
<li class="chapter" data-level="5.2" data-path="similarities.html"><a href="similarities.html#macron"><i class="fa fa-check"></i><b>5.2</b> Macron</a></li>
<li class="chapter" data-level="5.3" data-path="similarities.html"><a href="similarities.html#comparison"><i class="fa fa-check"></i><b>5.3</b> Comparison</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="topic-modelling.html"><a href="topic-modelling.html"><i class="fa fa-check"></i><b>6</b> Topic Modelling</a><ul>
<li class="chapter" data-level="6.1" data-path="topic-modelling.html"><a href="topic-modelling.html#boris-johnson-7"><i class="fa fa-check"></i><b>6.1</b> Boris Johnson</a><ul>
<li class="chapter" data-level="6.1.1" data-path="topic-modelling.html"><a href="topic-modelling.html#lsa"><i class="fa fa-check"></i><b>6.1.1</b> LSA</a></li>
<li class="chapter" data-level="6.1.2" data-path="topic-modelling.html"><a href="topic-modelling.html#lda"><i class="fa fa-check"></i><b>6.1.2</b> LDA</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="topic-modelling.html"><a href="topic-modelling.html#macron-1"><i class="fa fa-check"></i><b>6.2</b> Macron</a><ul>
<li class="chapter" data-level="6.2.1" data-path="topic-modelling.html"><a href="topic-modelling.html#lsa-1"><i class="fa fa-check"></i><b>6.2.1</b> LSA</a></li>
<li class="chapter" data-level="6.2.2" data-path="topic-modelling.html"><a href="topic-modelling.html#lda-1"><i class="fa fa-check"></i><b>6.2.2</b> LDA</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="word-embedding.html"><a href="word-embedding.html"><i class="fa fa-check"></i><b>7</b> Word Embedding</a><ul>
<li class="chapter" data-level="7.1" data-path="word-embedding.html"><a href="word-embedding.html#boris-johnson-8"><i class="fa fa-check"></i><b>7.1</b> Boris Johnson</a></li>
<li class="chapter" data-level="7.2" data-path="word-embedding.html"><a href="word-embedding.html#macron-2"><i class="fa fa-check"></i><b>7.2</b> Macron</a></li>
<li class="chapter" data-level="7.3" data-path="word-embedding.html"><a href="word-embedding.html#comparison-1"><i class="fa fa-check"></i><b>7.3</b> Comparison</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="supervised-learning.html"><a href="supervised-learning.html"><i class="fa fa-check"></i><b>8</b> Supervised learning</a><ul>
<li class="chapter" data-level="8.1" data-path="supervised-learning.html"><a href="supervised-learning.html#lsa-2"><i class="fa fa-check"></i><b>8.1</b> LSA</a></li>
<li class="chapter" data-level="8.2" data-path="supervised-learning.html"><a href="supervised-learning.html#random-forest"><i class="fa fa-check"></i><b>8.2</b> Random forest</a></li>
<li class="chapter" data-level="8.3" data-path="supervised-learning.html"><a href="supervised-learning.html#improving-the-features"><i class="fa fa-check"></i><b>8.3</b> Improving the features</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="conclusion.html"><a href="conclusion.html"><i class="fa fa-check"></i><b>9</b> Conclusion</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Dicours Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="word-embedding" class="section level1">
<h1><span class="header-section-number">Chapter 7</span> Word Embedding</h1>
<div id="boris-johnson-8" class="section level2">
<h2><span class="header-section-number">7.1</span> Boris Johnson</h2>
<p>Here, we compute the co-occurence matrix. We use the fcm function from quanteda. We use a window lenght 5.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">speech.coo.boris&lt;-<span class="kw">fcm</span>(corpus_boris,<span class="dt">context=</span><span class="st">&quot;window&quot;</span>,<span class="dt">window=</span><span class="dv">5</span>, <span class="dt">tri=</span><span class="ot">FALSE</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">p&lt;-<span class="dv">2</span> <span class="co">#word embedding dimension</span>
speech.glove.boris&lt;-GlobalVectors$<span class="kw">new</span>(<span class="dt">rank =</span> p,<span class="dt">x_max =</span> <span class="dv">10</span>) <span class="co">#xmas is a neede technical option</span>
speech.weC.boris&lt;-speech.glove.boris$<span class="kw">fit_transform</span>(speech.coo.boris)
<span class="co">#&gt; INFO  [19:01:31.632] epoch 1, loss 0.0346 </span>
<span class="co">#&gt; INFO  [19:01:31.784] epoch 2, loss 0.0245 </span>
<span class="co">#&gt; INFO  [19:01:31.826] epoch 3, loss 0.0225 </span>
<span class="co">#&gt; INFO  [19:01:31.833] epoch 4, loss 0.0215 </span>
<span class="co">#&gt; INFO  [19:01:31.843] epoch 5, loss 0.0207 </span>
<span class="co">#&gt; INFO  [19:01:31.854] epoch 6, loss 0.0201 </span>
<span class="co">#&gt; INFO  [19:01:31.864] epoch 7, loss 0.0195 </span>
<span class="co">#&gt; INFO  [19:01:31.873] epoch 8, loss 0.0189 </span>
<span class="co">#&gt; INFO  [19:01:31.887] epoch 9, loss 0.0183 </span>
<span class="co">#&gt; INFO  [19:01:31.896] epoch 10, loss 0.0177</span></code></pre></div>
<p>For illustration purpose, we now plot the 50 most used terms</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n.w.boris&lt;-<span class="kw">apply</span>(corpus_boris.dfm,<span class="dv">2</span>,sum) <span class="co">#compute the number of times each term is used</span>
index&lt;-<span class="kw">order</span>(n.w.boris,<span class="dt">decreasing =</span> <span class="ot">TRUE</span>)[<span class="dv">1</span>:<span class="dv">50</span>]
<span class="kw">plot</span>(speech.weC.boris[index,],<span class="dt">type =</span> <span class="st">&quot;n&quot;</span>,<span class="dt">xlab =</span> <span class="st">&quot;Dimension 1&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;Dimendion 2&quot;</span>)
<span class="kw">text</span>(<span class="dt">x=</span>speech.weC.boris[index,],<span class="dt">labels =</span> <span class="kw">rownames</span>(speech.weC.boris[index,]))</code></pre></div>
<p><img src="Text-Mining_files/figure-html/unnamed-chunk-59-1.png" width="70%" style="display: block; margin: auto;" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">speech.dtm &lt;-<span class="st"> </span>corpus_boris.dfm
speech.rwmd.model.boris&lt;-RelaxedWordMoversDistance$<span class="kw">new</span>(corpus_boris.dfm,speech.weC.boris)
speech.rwms.boris&lt;-speech.rwmd.model.boris$<span class="kw">sim2</span>(corpus_boris.dfm)
speech.rwmd.boris&lt;-speech.rwmd.model.boris$<span class="kw">dist2</span>(corpus_boris.dfm)

speech.hc.boris&lt;-<span class="kw">hclust</span>(<span class="kw">as.dist</span>(speech.rwmd.boris))
<span class="kw">plot</span>(speech.hc.boris,<span class="dt">cex=</span><span class="fl">0.8</span>)</code></pre></div>
<p><img src="Text-Mining_files/figure-html/unnamed-chunk-60-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>We can observe that there is some coherence within the groups in terms the date of the speech.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">speech.cl.boris&lt;-<span class="st"> </span><span class="kw">cutree</span>(speech.hc.boris,<span class="dt">k=</span><span class="dv">4</span>)
corpus_boris.dfm[speech.cl.boris==<span class="dv">1</span>,]
<span class="co">#&gt; Document-feature matrix of: 3 documents, 797 features (69.4% sparse).</span>
<span class="co">#&gt;        features</span>
<span class="co">#&gt; docs    morning government&#39;s cobr emergency committee coronavirus</span>
<span class="co">#&gt;   text1       1            2    1         1         1           3</span>
<span class="co">#&gt;   text2       0            1    0         1         1           2</span>
<span class="co">#&gt;   text4       0            0    0         1         0           2</span>
<span class="co">#&gt;        features</span>
<span class="co">#&gt; docs    outbreak first scotland minister</span>
<span class="co">#&gt;   text1        5     4        1        3</span>
<span class="co">#&gt;   text2        0     0        1        1</span>
<span class="co">#&gt;   text4        0     0        0        0</span>
<span class="co">#&gt; [ reached max_nfeat ... 787 more features ]</span></code></pre></div>
</div>
<div id="macron-2" class="section level2">
<h2><span class="header-section-number">7.2</span> Macron</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">speech.coo.macron&lt;-<span class="kw">fcm</span>(corpus_macron,<span class="dt">context=</span><span class="st">&quot;window&quot;</span>,<span class="dt">window=</span><span class="dv">5</span>, <span class="dt">tri=</span><span class="ot">FALSE</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">p&lt;-<span class="dv">2</span> <span class="co">#word embedding dimension</span>
speech.glove.macron&lt;-GlobalVectors$<span class="kw">new</span>(<span class="dt">rank =</span> p,<span class="dt">x_max =</span> <span class="dv">10</span>) <span class="co">#xmas is a neede technical option</span>
speech.weC.macron&lt;-speech.glove.macron$<span class="kw">fit_transform</span>(speech.coo.macron)
<span class="co">#&gt; INFO  [19:01:36.821] epoch 1, loss 0.0239 </span>
<span class="co">#&gt; INFO  [19:01:36.840] epoch 2, loss 0.0176 </span>
<span class="co">#&gt; INFO  [19:01:36.858] epoch 3, loss 0.0161 </span>
<span class="co">#&gt; INFO  [19:01:36.876] epoch 4, loss 0.0153 </span>
<span class="co">#&gt; INFO  [19:01:36.886] epoch 5, loss 0.0147 </span>
<span class="co">#&gt; INFO  [19:01:36.899] epoch 6, loss 0.0142 </span>
<span class="co">#&gt; INFO  [19:01:36.913] epoch 7, loss 0.0137 </span>
<span class="co">#&gt; INFO  [19:01:36.923] epoch 8, loss 0.0131 </span>
<span class="co">#&gt; INFO  [19:01:36.933] epoch 9, loss 0.0125 </span>
<span class="co">#&gt; INFO  [19:01:36.943] epoch 10, loss 0.0119</span></code></pre></div>
<p>For illustration purpose, we now plot the 50 most used terms</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n.w.macron&lt;-<span class="kw">apply</span>(corpus_macron.dfm,<span class="dv">2</span>,sum) <span class="co">#compute the number of times each term is used</span>
index&lt;-<span class="kw">order</span>(n.w.macron,<span class="dt">decreasing =</span> <span class="ot">TRUE</span>)[<span class="dv">1</span>:<span class="dv">50</span>]
<span class="kw">plot</span>(speech.weC.macron[index,],<span class="dt">type =</span> <span class="st">&quot;n&quot;</span>,<span class="dt">xlab =</span> <span class="st">&quot;Dimension 1&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;Dimendion 2&quot;</span>)
<span class="kw">text</span>(<span class="dt">x=</span>speech.weC.macron[index,],<span class="dt">labels =</span> <span class="kw">rownames</span>(speech.weC.macron[index,]))</code></pre></div>
<p><img src="Text-Mining_files/figure-html/unnamed-chunk-64-1.png" width="70%" style="display: block; margin: auto;" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">speech.dtm.macron &lt;-<span class="st"> </span>corpus_macron.dfm
speech.rwmd.model.macron&lt;-RelaxedWordMoversDistance$<span class="kw">new</span>(corpus_macron.dfm,speech.weC.macron)
speech.rwms.macron&lt;-speech.rwmd.model.macron$<span class="kw">sim2</span>(corpus_macron.dfm)
speech.rwmd.macron&lt;-speech.rwmd.model.macron$<span class="kw">dist2</span>(corpus_macron.dfm)

speech.hc.macron&lt;-<span class="kw">hclust</span>(<span class="kw">as.dist</span>(speech.rwmd.macron))
<span class="kw">plot</span>(speech.hc.macron,<span class="dt">cex=</span><span class="fl">0.8</span>)</code></pre></div>
<p><img src="Text-Mining_files/figure-html/unnamed-chunk-65-1.png" width="70%" style="display: block; margin: auto;" /> We can observe that there is some coherence within the groups in terms the date of the speech.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">speech.cl.macron&lt;-<span class="st"> </span><span class="kw">cutree</span>(speech.hc.macron,<span class="dt">k=</span><span class="dv">2</span>)
corpus_macron.dfm[speech.cl.macron==<span class="dv">1</span>,]
<span class="co">#&gt; Document-feature matrix of: 2 documents, 1,469 features (47.4% sparse).</span>
<span class="co">#&gt;        features</span>
<span class="co">#&gt; docs    france dear past country spread virus covid-19 several</span>
<span class="co">#&gt;   text1     10    6    3       4      8    13        4       5</span>
<span class="co">#&gt;   text3      7    5    3      12      2    11        1       5</span>
<span class="co">#&gt;        features</span>
<span class="co">#&gt; docs    thousand fellow</span>
<span class="co">#&gt;   text1        2      4</span>
<span class="co">#&gt;   text3        1      1</span>
<span class="co">#&gt; [ reached max_nfeat ... 1,459 more features ]</span></code></pre></div>
</div>
<div id="comparison-1" class="section level2">
<h2><span class="header-section-number">7.3</span> Comparison</h2>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="topic-modelling.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="supervised-learning.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
