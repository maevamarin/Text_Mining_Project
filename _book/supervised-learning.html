<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 8 Supervised learning | Dicours Analysis</title>
  <meta name="description" content="Chapter 8 Supervised learning | Dicours Analysis" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 8 Supervised learning | Dicours Analysis" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 8 Supervised learning | Dicours Analysis" />
  
  
  

<meta name="author" content="EugÃ©nie Mathieu, Maeva Marin, Hadrien Renger, Wajma Nazim" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="word-embedding.html"/>
<link rel="next" href="conclusion.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<<<<<<< HEAD
<script src="libs/htmlwidgets-1.5.1/htmlwidgets.js"></script>
=======
<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.2/htmlwidgets.js"></script>
>>>>>>> 29935c5794a00d63f04fc627797334b4417963c0
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.16/datatables.js"></script>
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.20/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk-1.1.0.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.0.1/js/crosstalk.min.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Basic introduction</a></li>
<li class="chapter" data-level="2" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>2</b> Introduction</a><ul>
<li class="chapter" data-level="2.1" data-path="introduction.html"><a href="introduction.html#overview-and-motivation"><i class="fa fa-check"></i><b>2.1</b> Overview and Motivation</a></li>
<li class="chapter" data-level="2.2" data-path="introduction.html"><a href="introduction.html#data-loadind"><i class="fa fa-check"></i><b>2.2</b> Data loadind</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="eda.html"><a href="eda.html"><i class="fa fa-check"></i><b>3</b> EDA</a><ul>
<li class="chapter" data-level="3.1" data-path="eda.html"><a href="eda.html#data-acquisition"><i class="fa fa-check"></i><b>3.1</b> Data Acquisition</a><ul>
<li class="chapter" data-level="3.1.1" data-path="eda.html"><a href="eda.html#emmanuel-macron"><i class="fa fa-check"></i><b>3.1.1</b> Emmanuel Macron</a></li>
<li class="chapter" data-level="3.1.2" data-path="eda.html"><a href="eda.html#boris-johnson"><i class="fa fa-check"></i><b>3.1.2</b> Boris Johnson</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="eda.html"><a href="eda.html#tokenisation-lemmatization-cleaning"><i class="fa fa-check"></i><b>3.2</b> Tokenisation, Lemmatization &amp; Cleaning</a><ul>
<li class="chapter" data-level="3.2.1" data-path="eda.html"><a href="eda.html#emmanuel-macron-1"><i class="fa fa-check"></i><b>3.2.1</b> Emmanuel Macron</a></li>
<li class="chapter" data-level="3.2.2" data-path="eda.html"><a href="eda.html#boris-johnson-1"><i class="fa fa-check"></i><b>3.2.2</b> Boris Johnson</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="eda.html"><a href="eda.html#document-term-matrix-dtm"><i class="fa fa-check"></i><b>3.3</b> Document-Term Matrix DTM</a><ul>
<li class="chapter" data-level="3.3.1" data-path="eda.html"><a href="eda.html#table"><i class="fa fa-check"></i><b>3.3.1</b> Table</a></li>
<li class="chapter" data-level="3.3.2" data-path="eda.html"><a href="eda.html#most-frequent-words"><i class="fa fa-check"></i><b>3.3.2</b> Most frequent words</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="eda.html"><a href="eda.html#tf-idf"><i class="fa fa-check"></i><b>3.4</b> TF-IDF</a><ul>
<li class="chapter" data-level="3.4.1" data-path="eda.html"><a href="eda.html#emmanuel-macron-2"><i class="fa fa-check"></i><b>3.4.1</b> Emmanuel Macron</a></li>
<li class="chapter" data-level="3.4.2" data-path="eda.html"><a href="eda.html#boris-johnson-2"><i class="fa fa-check"></i><b>3.4.2</b> Boris Johnson</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="eda.html"><a href="eda.html#cloud-of-words"><i class="fa fa-check"></i><b>3.5</b> Cloud of Words</a><ul>
<li class="chapter" data-level="3.5.1" data-path="eda.html"><a href="eda.html#usind-dfm"><i class="fa fa-check"></i><b>3.5.1</b> Usind DFM</a></li>
<li class="chapter" data-level="3.5.2" data-path="eda.html"><a href="eda.html#using-tf-idf"><i class="fa fa-check"></i><b>3.5.2</b> Using TF-IDF</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="eda.html"><a href="eda.html#lexical-divesity-token-type-ratio-ttr"><i class="fa fa-check"></i><b>3.6</b> Lexical Divesity Token Type Ratio TTR</a><ul>
<li class="chapter" data-level="3.6.1" data-path="eda.html"><a href="eda.html#emmanuel-macron-3"><i class="fa fa-check"></i><b>3.6.1</b> Emmanuel Macron</a></li>
<li class="chapter" data-level="3.6.2" data-path="eda.html"><a href="eda.html#boris-johnson-3"><i class="fa fa-check"></i><b>3.6.2</b> Boris Johnson</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="eda.html"><a href="eda.html#zipfs-law"><i class="fa fa-check"></i><b>3.7</b> Zipf's Law</a><ul>
<li class="chapter" data-level="3.7.1" data-path="eda.html"><a href="eda.html#emmanuel-macron-4"><i class="fa fa-check"></i><b>3.7.1</b> Emmanuel Macron</a></li>
<li class="chapter" data-level="3.7.2" data-path="eda.html"><a href="eda.html#boris-johnson-4"><i class="fa fa-check"></i><b>3.7.2</b> Boris Johnson</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="eda.html"><a href="eda.html#yules-index"><i class="fa fa-check"></i><b>3.8</b> Yule's index</a><ul>
<li class="chapter" data-level="3.8.1" data-path="eda.html"><a href="eda.html#emmanuel-macron-5"><i class="fa fa-check"></i><b>3.8.1</b> Emmanuel Macron</a></li>
<li class="chapter" data-level="3.8.2" data-path="eda.html"><a href="eda.html#boris-johnson-5"><i class="fa fa-check"></i><b>3.8.2</b> Boris Johnson</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="eda.html"><a href="eda.html#mattr"><i class="fa fa-check"></i><b>3.9</b> MATTR</a><ul>
<li class="chapter" data-level="3.9.1" data-path="eda.html"><a href="eda.html#emmanuel-macron-6"><i class="fa fa-check"></i><b>3.9.1</b> Emmanuel Macron</a></li>
<li class="chapter" data-level="3.9.2" data-path="eda.html"><a href="eda.html#boris-johnson-6"><i class="fa fa-check"></i><b>3.9.2</b> Boris Johnson</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html"><i class="fa fa-check"></i><b>4</b> Sentiment Analysis</a><ul>
<li class="chapter" data-level="4.1" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html#analysis-with-the-nrc-library"><i class="fa fa-check"></i><b>4.1</b> Analysis with the &quot;nrc&quot; library</a></li>
<li class="chapter" data-level="4.2" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html#analysis-with-the-lsd2015-dictionnary"><i class="fa fa-check"></i><b>4.2</b> Analysis with the LSD2015 dictionnary</a></li>
<li class="chapter" data-level="4.3" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html#analysis-with-the-afinn-dictionnary"><i class="fa fa-check"></i><b>4.3</b> Analysis with the &quot;afinn&quot; dictionnary</a><ul>
<li class="chapter" data-level="4.3.1" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html#analysis-using-nrc-dictionnary-and-valence-shifters"><i class="fa fa-check"></i><b>4.3.1</b> Analysis using &quot;nrc&quot;&quot; dictionnary and valence shifters</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="similarities.html"><a href="similarities.html"><i class="fa fa-check"></i><b>5</b> Similarities</a><ul>
<li class="chapter" data-level="5.1" data-path="similarities.html"><a href="similarities.html#boris"><i class="fa fa-check"></i><b>5.1</b> Boris</a></li>
<li class="chapter" data-level="5.2" data-path="similarities.html"><a href="similarities.html#macron"><i class="fa fa-check"></i><b>5.2</b> Macron</a></li>
<li class="chapter" data-level="5.3" data-path="similarities.html"><a href="similarities.html#comparison"><i class="fa fa-check"></i><b>5.3</b> Comparison</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="topic-modelling.html"><a href="topic-modelling.html"><i class="fa fa-check"></i><b>6</b> Topic Modelling</a><ul>
<li class="chapter" data-level="6.1" data-path="topic-modelling.html"><a href="topic-modelling.html#boris-johnson-7"><i class="fa fa-check"></i><b>6.1</b> Boris Johnson</a><ul>
<li class="chapter" data-level="6.1.1" data-path="topic-modelling.html"><a href="topic-modelling.html#lsa"><i class="fa fa-check"></i><b>6.1.1</b> LSA</a></li>
<li class="chapter" data-level="6.1.2" data-path="topic-modelling.html"><a href="topic-modelling.html#lda"><i class="fa fa-check"></i><b>6.1.2</b> LDA</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="topic-modelling.html"><a href="topic-modelling.html#macron-1"><i class="fa fa-check"></i><b>6.2</b> Macron</a><ul>
<li class="chapter" data-level="6.2.1" data-path="topic-modelling.html"><a href="topic-modelling.html#lsa-1"><i class="fa fa-check"></i><b>6.2.1</b> LSA</a></li>
<li class="chapter" data-level="6.2.2" data-path="topic-modelling.html"><a href="topic-modelling.html#lda-1"><i class="fa fa-check"></i><b>6.2.2</b> LDA</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="word-embedding.html"><a href="word-embedding.html"><i class="fa fa-check"></i><b>7</b> Word Embedding</a><ul>
<li class="chapter" data-level="7.1" data-path="word-embedding.html"><a href="word-embedding.html#boris-johnson-8"><i class="fa fa-check"></i><b>7.1</b> Boris Johnson</a></li>
<li class="chapter" data-level="7.2" data-path="word-embedding.html"><a href="word-embedding.html#macron-2"><i class="fa fa-check"></i><b>7.2</b> Macron</a></li>
<li class="chapter" data-level="7.3" data-path="word-embedding.html"><a href="word-embedding.html#comparison-1"><i class="fa fa-check"></i><b>7.3</b> Comparison</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="supervised-learning.html"><a href="supervised-learning.html"><i class="fa fa-check"></i><b>8</b> Supervised learning</a><ul>
<li class="chapter" data-level="8.1" data-path="supervised-learning.html"><a href="supervised-learning.html#lsa-2"><i class="fa fa-check"></i><b>8.1</b> LSA</a></li>
<li class="chapter" data-level="8.2" data-path="supervised-learning.html"><a href="supervised-learning.html#random-forest"><i class="fa fa-check"></i><b>8.2</b> Random forest</a></li>
<li class="chapter" data-level="8.3" data-path="supervised-learning.html"><a href="supervised-learning.html#improving-the-features"><i class="fa fa-check"></i><b>8.3</b> Improving the features</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="conclusion.html"><a href="conclusion.html"><i class="fa fa-check"></i><b>9</b> Conclusion</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Dicours Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="supervised-learning" class="section level1">
<h1><span class="header-section-number">Chapter 8</span> Supervised learning</h1>
<<<<<<< HEAD
<p>In this section, we use supervised learning to develop a classifier of speech. The final aim is to be able to classify a speech from Boris Johnson or Emmanuel Macron. Therefore we are going to combine the dataframe of Boris with the dataframe of Macron. And because we donât have enough text, we are going to split the text into sentence in order to have enough data.</p>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb89-1" data-line-number="1"><span class="co">##Boris Johnson</span></a>
<a class="sourceLine" id="cb89-2" data-line-number="2">boris_<span class="dv">2</span>&lt;-<span class="kw">as_tibble</span>(<span class="kw">c</span>(boris9mars,boris12mars,boris16mars,boris18mars,boris19mars,boris20mars,boris22mars)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb89-3" data-line-number="3"><span class="st">  </span><span class="kw">rename</span>(</a>
<a class="sourceLine" id="cb89-4" data-line-number="4">  <span class="dt">text=</span>value)</a>
<a class="sourceLine" id="cb89-5" data-line-number="5">author=<span class="st">&quot;Boris Johnson&quot;</span></a>
<a class="sourceLine" id="cb89-6" data-line-number="6">boris_supervised&lt;-<span class="st"> </span><span class="kw">cbind</span>(boris_<span class="dv">2</span>, author)</a>
<a class="sourceLine" id="cb89-7" data-line-number="7"></a>
<a class="sourceLine" id="cb89-8" data-line-number="8">boris_<span class="dv">2</span>_sentence&lt;-<span class="kw">get_sentences</span>(boris_supervised)</a>
<a class="sourceLine" id="cb89-9" data-line-number="9"><span class="co">##Emmanuel Macron</span></a>
<a class="sourceLine" id="cb89-10" data-line-number="10">Macron_<span class="dv">2</span>&lt;-<span class="kw">as_tibble</span>(<span class="kw">c</span>(macron12march,macron16march,macron13april)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb89-11" data-line-number="11"><span class="st">  </span><span class="kw">rename</span>(</a>
<a class="sourceLine" id="cb89-12" data-line-number="12">    <span class="dt">text =</span> value)</a>
<a class="sourceLine" id="cb89-13" data-line-number="13"></a>
<a class="sourceLine" id="cb89-14" data-line-number="14">author=<span class="st">&quot;Macron&quot;</span></a>
<a class="sourceLine" id="cb89-15" data-line-number="15">macron_supervised&lt;-<span class="st"> </span><span class="kw">cbind</span>(Macron_<span class="dv">2</span>, author)</a>
<a class="sourceLine" id="cb89-16" data-line-number="16"></a>
<a class="sourceLine" id="cb89-17" data-line-number="17">macron_<span class="dv">2</span>_sentence&lt;-<span class="kw">get_sentences</span>(macron_supervised)</a>
<a class="sourceLine" id="cb89-18" data-line-number="18"></a>
<a class="sourceLine" id="cb89-19" data-line-number="19"><span class="co">##Combine the 2 dataframes</span></a>
<a class="sourceLine" id="cb89-20" data-line-number="20">combine &lt;-<span class="st"> </span><span class="kw">rbind</span>(boris_<span class="dv">2</span>_sentence, macron_<span class="dv">2</span>_sentence)</a>
<a class="sourceLine" id="cb89-21" data-line-number="21"></a>
<a class="sourceLine" id="cb89-22" data-line-number="22"></a>
<a class="sourceLine" id="cb89-23" data-line-number="23"><span class="co">## Tokenization</span></a>
<a class="sourceLine" id="cb89-24" data-line-number="24">combine_corpus&lt;-<span class="kw">corpus</span>(combine)</a>
<a class="sourceLine" id="cb89-25" data-line-number="25">combine_tokens&lt;-<span class="st"> </span><span class="kw">tokens</span>(combine_corpus, <span class="dt">remove_numbers =</span> <span class="ot">TRUE</span>, <span class="dt">remove_punct =</span> <span class="ot">TRUE</span>, <span class="dt">remove_symbols =</span> <span class="ot">TRUE</span>, <span class="dt">remove_separators =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb89-26" data-line-number="26"></a>
<a class="sourceLine" id="cb89-27" data-line-number="27"><span class="co">##combi Lemmatization</span></a>
<a class="sourceLine" id="cb89-28" data-line-number="28"></a>
<a class="sourceLine" id="cb89-29" data-line-number="29">combine_tokens &lt;-<span class="st"> </span><span class="kw">tokens_replace</span>(combine_tokens, <span class="dt">pattern=</span>hash_lemmas<span class="op">$</span>token, <span class="dt">replacement =</span> hash_lemmas<span class="op">$</span>lemma)</a>
<a class="sourceLine" id="cb89-30" data-line-number="30"></a>
<a class="sourceLine" id="cb89-31" data-line-number="31"><span class="co">## Cleaning</span></a>
<a class="sourceLine" id="cb89-32" data-line-number="32">combine_tokens =<span class="st"> </span>combine_tokens <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb89-33" data-line-number="33"><span class="st">  </span><span class="kw">tokens_tolower</span>() <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb89-34" data-line-number="34"><span class="st">  </span><span class="kw">tokens_remove</span>(<span class="kw">stopwords</span>(<span class="st">&quot;english&quot;</span>))</a>
<a class="sourceLine" id="cb89-35" data-line-number="35"></a>
<a class="sourceLine" id="cb89-36" data-line-number="36">y&lt;-<span class="kw">factor</span>(<span class="kw">docvars</span>(combine_tokens,<span class="st">&quot;author&quot;</span>))</a></code></pre></div>
<p>Then, we build the featues. To this aim, we first compute the DTM matrix.</p>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb90-1" data-line-number="1">combine.dfm&lt;-<span class="kw">dfm</span>(combine_tokens)</a>
<a class="sourceLine" id="cb90-2" data-line-number="2">combine.dfm</a>
<a class="sourceLine" id="cb90-3" data-line-number="3"><span class="co">#&gt; Document-feature matrix of: 1,088 documents, 1,700 features (99.6% sparse) and 3 docvars.</span></a>
<a class="sourceLine" id="cb90-4" data-line-number="4"><span class="co">#&gt;        features</span></a>
<a class="sourceLine" id="cb90-5" data-line-number="5"><span class="co">#&gt; docs    morning meeting government&#39;s cobr emergency committee</span></a>
<a class="sourceLine" id="cb90-6" data-line-number="6"><span class="co">#&gt;   text1       0       0            0    0         0         0</span></a>
<a class="sourceLine" id="cb90-7" data-line-number="7"><span class="co">#&gt;   text2       1       0            1    1         1         1</span></a>
<a class="sourceLine" id="cb90-8" data-line-number="8"><span class="co">#&gt;   text3       0       0            0    0         0         0</span></a>
<a class="sourceLine" id="cb90-9" data-line-number="9"><span class="co">#&gt;   text4       0       0            0    0         0         0</span></a>
<a class="sourceLine" id="cb90-10" data-line-number="10"><span class="co">#&gt;   text5       0       0            0    0         0         0</span></a>
<a class="sourceLine" id="cb90-11" data-line-number="11"><span class="co">#&gt;   text6       0       0            0    0         0         0</span></a>
<a class="sourceLine" id="cb90-12" data-line-number="12"><span class="co">#&gt;        features</span></a>
<a class="sourceLine" id="cb90-13" data-line-number="13"><span class="co">#&gt; docs    coronavirus outbreak first scotland</span></a>
<a class="sourceLine" id="cb90-14" data-line-number="14"><span class="co">#&gt;   text1           0        0     0        0</span></a>
<a class="sourceLine" id="cb90-15" data-line-number="15"><span class="co">#&gt;   text2           1        1     0        0</span></a>
<a class="sourceLine" id="cb90-16" data-line-number="16"><span class="co">#&gt;   text3           0        0     0        0</span></a>
<a class="sourceLine" id="cb90-17" data-line-number="17"><span class="co">#&gt;   text4           0        0     0        0</span></a>
<a class="sourceLine" id="cb90-18" data-line-number="18"><span class="co">#&gt;   text5           0        0     3        1</span></a>
<a class="sourceLine" id="cb90-19" data-line-number="19"><span class="co">#&gt;   text6           0        0     0        0</span></a>
<a class="sourceLine" id="cb90-20" data-line-number="20"><span class="co">#&gt; [ reached max_ndoc ... 1,082 more documents, reached max_nfeat ... 1,690 more features ]</span></a></code></pre></div>
<div id="lsa-2" class="section level2">
<h2><span class="header-section-number">8.1</span> LSA</h2>
<p>Because of the huge number of tokens, the feature matrix hence obtained may be too big to train a model in a reasonable amount of time. We thus apply a reduction dimension technoque in order to obtain less feature but still kepp the relevant informations. LSA is perfect to this.
As a first trialm we target 30 dimensions ( 30 subjects)</p>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb91-1" data-line-number="1"></a>
<a class="sourceLine" id="cb91-2" data-line-number="2">combine_corpus.dfm &lt;-<span class="st"> </span><span class="kw">dfm</span>(combine_corpus)</a>
<a class="sourceLine" id="cb91-3" data-line-number="3">cmod&lt;-<span class="kw">textmodel_lsa</span>(combine_corpus.dfm,<span class="dt">nd=</span><span class="dv">30</span>)</a></code></pre></div>
</div>
<div id="random-forest" class="section level2">
<h2><span class="header-section-number">8.2</span> Random forest</h2>
<p>First we need to shape the data in a dataframe. We separate the text into sentence in order to have a more consistent and robust dataframe.
Then we call for the training. In this simple context, in order to illustrate the concepts without too long computation times, we will limit ourselves to just one training set and one test set in a 08/02 pattern.</p>
<div class="sourceCode" id="cb92"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb92-1" data-line-number="1">df&lt;-<span class="kw">data.frame</span>(<span class="dt">Class=</span>y, <span class="dt">x=</span>cmod<span class="op">$</span>docs)</a>
<a class="sourceLine" id="cb92-2" data-line-number="2">index.tr&lt;-<span class="kw">sample</span>(<span class="dt">size =</span> <span class="kw">round</span>(<span class="fl">0.8</span><span class="op">*</span><span class="kw">length</span>(y)),<span class="dt">x=</span><span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(y)),<span class="dt">replace =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb92-3" data-line-number="3"></a>
<a class="sourceLine" id="cb92-4" data-line-number="4">df.tr&lt;-df[index.tr,]</a>
<a class="sourceLine" id="cb92-5" data-line-number="5">df.te&lt;-df[<span class="op">-</span>index.tr,]</a>
<a class="sourceLine" id="cb92-6" data-line-number="6"></a>
<a class="sourceLine" id="cb92-7" data-line-number="7"></a>
<a class="sourceLine" id="cb92-8" data-line-number="8">combine.fit&lt;-<span class="kw">ranger</span>(Class<span class="op">~</span>.,</a>
<a class="sourceLine" id="cb92-9" data-line-number="9">                    <span class="dt">data =</span> df.tr)</a>
<a class="sourceLine" id="cb92-10" data-line-number="10">pred.te&lt;-<span class="kw">predict</span>(combine.fit,df.te)</a></code></pre></div>
<p>In order to see the prediction quality of the model, we call the confusionMatrix function in the caret package</p>
<div class="sourceCode" id="cb93"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb93-1" data-line-number="1"><span class="kw">confusionMatrix</span>(<span class="dt">data=</span>pred.te<span class="op">$</span>predictions,<span class="dt">reference =</span> df.te<span class="op">$</span>Class)</a>
<a class="sourceLine" id="cb93-2" data-line-number="2"><span class="co">#&gt; Confusion Matrix and Statistics</span></a>
<a class="sourceLine" id="cb93-3" data-line-number="3"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb93-4" data-line-number="4"><span class="co">#&gt;                Reference</span></a>
<a class="sourceLine" id="cb93-5" data-line-number="5"><span class="co">#&gt; Prediction      Boris Johnson Macron</span></a>
<a class="sourceLine" id="cb93-6" data-line-number="6"><span class="co">#&gt;   Boris Johnson            90      9</span></a>
<a class="sourceLine" id="cb93-7" data-line-number="7"><span class="co">#&gt;   Macron                   38     81</span></a>
<a class="sourceLine" id="cb93-8" data-line-number="8"><span class="co">#&gt;                                         </span></a>
<a class="sourceLine" id="cb93-9" data-line-number="9"><span class="co">#&gt;                Accuracy : 0.784         </span></a>
<a class="sourceLine" id="cb93-10" data-line-number="10"><span class="co">#&gt;                  95% CI : (0.724, 0.837)</span></a>
<a class="sourceLine" id="cb93-11" data-line-number="11"><span class="co">#&gt;     No Information Rate : 0.587         </span></a>
<a class="sourceLine" id="cb93-12" data-line-number="12"><span class="co">#&gt;     P-Value [Acc &gt; NIR] : 5.99e-10      </span></a>
<a class="sourceLine" id="cb93-13" data-line-number="13"><span class="co">#&gt;                                         </span></a>
<a class="sourceLine" id="cb93-14" data-line-number="14"><span class="co">#&gt;                   Kappa : 0.576         </span></a>
<a class="sourceLine" id="cb93-15" data-line-number="15"><span class="co">#&gt;                                         </span></a>
<a class="sourceLine" id="cb93-16" data-line-number="16"><span class="co">#&gt;  Mcnemar&#39;s Test P-Value : 4.42e-05      </span></a>
<a class="sourceLine" id="cb93-17" data-line-number="17"><span class="co">#&gt;                                         </span></a>
<a class="sourceLine" id="cb93-18" data-line-number="18"><span class="co">#&gt;             Sensitivity : 0.703         </span></a>
<a class="sourceLine" id="cb93-19" data-line-number="19"><span class="co">#&gt;             Specificity : 0.900         </span></a>
<a class="sourceLine" id="cb93-20" data-line-number="20"><span class="co">#&gt;          Pos Pred Value : 0.909         </span></a>
<a class="sourceLine" id="cb93-21" data-line-number="21"><span class="co">#&gt;          Neg Pred Value : 0.681         </span></a>
<a class="sourceLine" id="cb93-22" data-line-number="22"><span class="co">#&gt;              Prevalence : 0.587         </span></a>
<a class="sourceLine" id="cb93-23" data-line-number="23"><span class="co">#&gt;          Detection Rate : 0.413         </span></a>
<a class="sourceLine" id="cb93-24" data-line-number="24"><span class="co">#&gt;    Detection Prevalence : 0.454         </span></a>
<a class="sourceLine" id="cb93-25" data-line-number="25"><span class="co">#&gt;       Balanced Accuracy : 0.802         </span></a>
<a class="sourceLine" id="cb93-26" data-line-number="26"><span class="co">#&gt;                                         </span></a>
<a class="sourceLine" id="cb93-27" data-line-number="27"><span class="co">#&gt;        &#39;Positive&#39; Class : Boris Johnson </span></a>
<a class="sourceLine" id="cb93-28" data-line-number="28"><span class="co">#&gt; </span></a></code></pre></div>
=======
<p>In this section, we use supervised learning to develop a classifier of speech. The final aim is to be able to classify a speech from Boris Johnson or Emmanuel Macron. Therefore we are going to combine the dataframe of Boris with the dataframe of Macron. And because we don't have enough text, we are going to split the text into sentence in order to have enough data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">
##Boris Johnson
boris_2&lt;-<span class="kw">as_tibble</span>(<span class="kw">c</span>(boris9mars,boris12mars,boris16mars,boris18mars,boris19mars,boris20mars,boris22mars)) %&gt;%
<span class="st">  </span><span class="kw">rename</span>(
  <span class="dt">text=</span>value)
author=<span class="st">&quot;Boris Johnson&quot;</span>
boris_supervised&lt;-<span class="st"> </span><span class="kw">cbind</span>(boris_2, author)

boris_2_sentence&lt;-<span class="kw">get_sentences</span>(boris_supervised)
##Emmanuel Macron
Macron_2&lt;-<span class="kw">as_tibble</span>(<span class="kw">c</span>(macron12march,macron16march,macron13april)) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">rename</span>(
    <span class="dt">text =</span> value)

author=<span class="st">&quot;Macron&quot;</span>
macron_supervised&lt;-<span class="st"> </span><span class="kw">cbind</span>(Macron_2, author)

macron_2_sentence&lt;-<span class="kw">get_sentences</span>(macron_supervised)

##Combine the 2 dataframes
combine &lt;-<span class="st"> </span><span class="kw">rbind</span>(boris_2_sentence, macron_2_sentence)


## Tokenization
combine_corpus&lt;-<span class="kw">corpus</span>(combine)
combine_tokens&lt;-<span class="st"> </span><span class="kw">tokens</span>(combine_corpus, <span class="dt">remove_numbers =</span> <span class="ot">TRUE</span>, <span class="dt">remove_punct =</span> <span class="ot">TRUE</span>, <span class="dt">remove_symbols =</span> <span class="ot">TRUE</span>, <span class="dt">remove_separators =</span> <span class="ot">TRUE</span>)

##combi Lemmatization


combine_tokens &lt;-<span class="st"> </span><span class="kw">tokens_replace</span>(combine_tokens, <span class="dt">pattern=</span>hash_lemmas$token, <span class="dt">replacement =</span> hash_lemmas$lemma)


## Cleaning
combine_tokens =<span class="st"> </span>combine_tokens %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">tokens_tolower</span>() %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">tokens_remove</span>(<span class="kw">stopwords</span>(<span class="st">&quot;english&quot;</span>))
y
<span class="co">#&gt;   [1] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt;   [5] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt;   [9] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt;  [13] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt;  [17] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt;  [21] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt;  [25] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt;  [29] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt;  [33] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt;  [37] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt;  [41] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt;  [45] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt;  [49] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt;  [53] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt;  [57] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt;  [61] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt;  [65] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt;  [69] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt;  [73] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt;  [77] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt;  [81] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt;  [85] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt;  [89] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt;  [93] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt;  [97] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt; [101] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt; [105] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt; [109] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt; [113] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt; [117] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt; [121] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt; [125] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt; [129] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt; [133] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt; [137] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt; [141] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt; [145] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt; [149] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt; [153] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt; [157] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt; [161] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt; [165] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt; [169] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt; [173] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt; [177] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt; [181] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt; [185] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt; [189] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt; [193] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt; [197] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt; [201] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt; [205] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt; [209] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt; [213] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt; [217] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt; [221] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt; [225] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt; [229] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt; [233] Boris Johnson Boris Johnson Boris Johnson Boris Johnson</span>
<span class="co">#&gt; [237] Boris Johnson Boris Johnson Boris Johnson Macron       </span>
<span class="co">#&gt; [241] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [245] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [249] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [253] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [257] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [261] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [265] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [269] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [273] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [277] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [281] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [285] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [289] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [293] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [297] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [301] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [305] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [309] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [313] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [317] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [321] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [325] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [329] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [333] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [337] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [341] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [345] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [349] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [353] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [357] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [361] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [365] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [369] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [373] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [377] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [381] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [385] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [389] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [393] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [397] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [401] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [405] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [409] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [413] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [417] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [421] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [425] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [429] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [433] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [437] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [441] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [445] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [449] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [453] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [457] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [461] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [465] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [469] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [473] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [477] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [481] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [485] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [489] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [493] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [497] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [501] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [505] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [509] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [513] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [517] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [521] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [525] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [529] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [533] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [537] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [541] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [545] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [549] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [553] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [557] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [561] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [565] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [569] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [573] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [577] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [581] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [585] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [589] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [593] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [597] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [601] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [605] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [609] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [613] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [617] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [621] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [625] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [629] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [633] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [637] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [641] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [645] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [649] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [653] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [657] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [661] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [665] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [669] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [673] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [677] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [681] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [685] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [689] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [693] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [697] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [701] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [705] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [709] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [713] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [717] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [721] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [725] Macron        Macron        Macron        Macron       </span>
<span class="co">#&gt; [729] Macron        Macron       </span>
<span class="co">#&gt; Levels: Boris Johnson Macron</span>
y&lt;-<span class="kw">factor</span>(<span class="kw">docvars</span>(combine_tokens,<span class="st">&quot;author&quot;</span>))</code></pre></div>
<p>Then, we build the featues. To this aim, we first compute the DTM matrix.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">combine.dfm&lt;-<span class="kw">dfm</span>(combine_tokens)
combine.dfm
<span class="co">#&gt; Document-feature matrix of: 771 documents, 1,691 features (99.4% sparse) and 3 docvars.</span>
<span class="co">#&gt;        features</span>
<span class="co">#&gt; docs    morning meeting government&#39;s cobr emergency committee</span>
<span class="co">#&gt;   text1       0       0            0    0         0         0</span>
<span class="co">#&gt;   text2       1       0            1    1         1         1</span>
<span class="co">#&gt;   text3       0       0            0    0         0         0</span>
<span class="co">#&gt;   text4       0       0            0    0         0         0</span>
<span class="co">#&gt;   text5       0       0            0    0         0         0</span>
<span class="co">#&gt;   text6       0       0            0    0         0         0</span>
<span class="co">#&gt;        features</span>
<span class="co">#&gt; docs    coronavirus outbreak first scotland</span>
<span class="co">#&gt;   text1           0        0     0        0</span>
<span class="co">#&gt;   text2           1        1     0        0</span>
<span class="co">#&gt;   text3           0        0     3        1</span>
<span class="co">#&gt;   text4           0        0     0        0</span>
<span class="co">#&gt;   text5           0        0     0        0</span>
<span class="co">#&gt;   text6           1        0     0        0</span>
<span class="co">#&gt; [ reached max_ndoc ... 765 more documents, reached max_nfeat ... 1,681 more features ]</span></code></pre></div>
<div id="lsa-2" class="section level2">
<h2><span class="header-section-number">8.1</span> LSA</h2>
<p>Because of the huge number of tokens, the feature matrix hence obtained may be too big to train a model in a reasonable amount of time. We thus apply a reduction dimension technoque in order to obtain less feature but still kepp the relevant informations. LSA is perfect to this. As a first trialm we target 30 dimensions ( 30 subjects)</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">
combine_corpus.dfm &lt;-<span class="st"> </span><span class="kw">dfm</span>(combine_corpus)
cmod&lt;-<span class="kw">textmodel_lsa</span>(combine_corpus.dfm,<span class="dt">nd=</span><span class="dv">30</span>)</code></pre></div>
</div>
<div id="random-forest" class="section level2">
<h2><span class="header-section-number">8.2</span> Random forest</h2>
<p>First we need to shape the data in a dataframe. We separate the text into sentence in order to have a more consistent and robust dataframe. Then we call for the training. In this simple context, in order to illustrate the concepts without too long computation times, we will limit ourselves to just one training set and one test set in a 08/02 pattern.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df&lt;-<span class="kw">data.frame</span>(<span class="dt">Class=</span>y, <span class="dt">x=</span>cmod$docs)
index.tr&lt;-<span class="kw">sample</span>(<span class="dt">size =</span> <span class="kw">round</span>(<span class="fl">0.8</span>*<span class="kw">length</span>(y)),<span class="dt">x=</span><span class="kw">c</span>(<span class="dv">1</span>:<span class="kw">length</span>(y)),<span class="dt">replace =</span> <span class="ot">FALSE</span>)

df.tr&lt;-df[index.tr,]
df.te&lt;-df[-index.tr,]


combine.fit&lt;-<span class="kw">ranger</span>(Class~.,
                    <span class="dt">data =</span> df.tr)
pred.te&lt;-<span class="kw">predict</span>(combine.fit,df.te)</code></pre></div>
<p>In order to see the prediction quality of the model, we call the confusionMatrix function in the caret package</p>
<<<<<<< HEAD
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb74-1" data-line-number="1"><span class="kw">confusionMatrix</span>(<span class="dt">data=</span>pred.te<span class="op">$</span>predictions,<span class="dt">reference =</span> df.te<span class="op">$</span>Class)</a>
<a class="sourceLine" id="cb74-2" data-line-number="2"><span class="co">#&gt; Confusion Matrix and Statistics</span></a>
<a class="sourceLine" id="cb74-3" data-line-number="3"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb74-4" data-line-number="4"><span class="co">#&gt;                Reference</span></a>
<a class="sourceLine" id="cb74-5" data-line-number="5"><span class="co">#&gt; Prediction      Boris Johnson Macron</span></a>
<a class="sourceLine" id="cb74-6" data-line-number="6"><span class="co">#&gt;   Boris Johnson            17      5</span></a>
<a class="sourceLine" id="cb74-7" data-line-number="7"><span class="co">#&gt;   Macron                   35     89</span></a>
<a class="sourceLine" id="cb74-8" data-line-number="8"><span class="co">#&gt;                                         </span></a>
<a class="sourceLine" id="cb74-9" data-line-number="9"><span class="co">#&gt;                Accuracy : 0.726         </span></a>
<a class="sourceLine" id="cb74-10" data-line-number="10"><span class="co">#&gt;                  95% CI : (0.646, 0.797)</span></a>
<a class="sourceLine" id="cb74-11" data-line-number="11"><span class="co">#&gt;     No Information Rate : 0.644         </span></a>
<a class="sourceLine" id="cb74-12" data-line-number="12"><span class="co">#&gt;     P-Value [Acc &gt; NIR] : 0.0218        </span></a>
<a class="sourceLine" id="cb74-13" data-line-number="13"><span class="co">#&gt;                                         </span></a>
<a class="sourceLine" id="cb74-14" data-line-number="14"><span class="co">#&gt;                   Kappa : 0.314         </span></a>
<a class="sourceLine" id="cb74-15" data-line-number="15"><span class="co">#&gt;                                         </span></a>
<a class="sourceLine" id="cb74-16" data-line-number="16"><span class="co">#&gt;  Mcnemar&#39;s Test P-Value : 4.53e-06      </span></a>
<a class="sourceLine" id="cb74-17" data-line-number="17"><span class="co">#&gt;                                         </span></a>
<a class="sourceLine" id="cb74-18" data-line-number="18"><span class="co">#&gt;             Sensitivity : 0.327         </span></a>
<a class="sourceLine" id="cb74-19" data-line-number="19"><span class="co">#&gt;             Specificity : 0.947         </span></a>
<a class="sourceLine" id="cb74-20" data-line-number="20"><span class="co">#&gt;          Pos Pred Value : 0.773         </span></a>
<a class="sourceLine" id="cb74-21" data-line-number="21"><span class="co">#&gt;          Neg Pred Value : 0.718         </span></a>
<a class="sourceLine" id="cb74-22" data-line-number="22"><span class="co">#&gt;              Prevalence : 0.356         </span></a>
<a class="sourceLine" id="cb74-23" data-line-number="23"><span class="co">#&gt;          Detection Rate : 0.116         </span></a>
<a class="sourceLine" id="cb74-24" data-line-number="24"><span class="co">#&gt;    Detection Prevalence : 0.151         </span></a>
<a class="sourceLine" id="cb74-25" data-line-number="25"><span class="co">#&gt;       Balanced Accuracy : 0.637         </span></a>
<a class="sourceLine" id="cb74-26" data-line-number="26"><span class="co">#&gt;                                         </span></a>
<a class="sourceLine" id="cb74-27" data-line-number="27"><span class="co">#&gt;        &#39;Positive&#39; Class : Boris Johnson </span></a>
<a class="sourceLine" id="cb74-28" data-line-number="28"><span class="co">#&gt; </span></a></code></pre></div>
=======
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confusionMatrix</span>(<span class="dt">data=</span>pred.te$predictions,<span class="dt">reference =</span> df.te$Class)
<span class="co">#&gt; Confusion Matrix and Statistics</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;                Reference</span>
<span class="co">#&gt; Prediction      Boris Johnson Macron</span>
<span class="co">#&gt;   Boris Johnson            29      7</span>
<span class="co">#&gt;   Macron                   30     88</span>
<span class="co">#&gt;                                         </span>
<span class="co">#&gt;                Accuracy : 0.76          </span>
<span class="co">#&gt;                  95% CI : (0.684, 0.825)</span>
<span class="co">#&gt;     No Information Rate : 0.617         </span>
<span class="co">#&gt;     P-Value [Acc &gt; NIR] : 0.000121      </span>
<span class="co">#&gt;                                         </span>
<span class="co">#&gt;                   Kappa : 0.451         </span>
<span class="co">#&gt;                                         </span>
<span class="co">#&gt;  Mcnemar&#39;s Test P-Value : 0.000298      </span>
<span class="co">#&gt;                                         </span>
<span class="co">#&gt;             Sensitivity : 0.492         </span>
<span class="co">#&gt;             Specificity : 0.926         </span>
<span class="co">#&gt;          Pos Pred Value : 0.806         </span>
<span class="co">#&gt;          Neg Pred Value : 0.746         </span>
<span class="co">#&gt;              Prevalence : 0.383         </span>
<span class="co">#&gt;          Detection Rate : 0.188         </span>
<span class="co">#&gt;    Detection Prevalence : 0.234         </span>
<span class="co">#&gt;       Balanced Accuracy : 0.709         </span>
<span class="co">#&gt;                                         </span>
<span class="co">#&gt;        &#39;Positive&#39; Class : Boris Johnson </span>
<span class="co">#&gt; </span></code></pre></div>
>>>>>>> 29935c5794a00d63f04fc627797334b4417963c0
>>>>>>> 38a3e356d3937ca2d4b6bf974a95a42157fd08d1
<p>We see an accuracy of 69.9%. Also a sensitivity of 40.4% and a specificity of 86.2%. The prediction quality is not well balanced between the 2 class. The model struggle to predict the negative class, which is Macron. It is probably because we there is less data of Macron.</p>
</div>
<div id="improving-the-features" class="section level2">
<h2><span class="header-section-number">8.3</span> Improving the features</h2>
<<<<<<< HEAD
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb75-1" data-line-number="1">nd.vec&lt;-<span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">5</span>,<span class="dv">25</span>,<span class="dv">50</span>,<span class="dv">100</span>,<span class="dv">500</span>,<span class="dv">1000</span>)</a>
<a class="sourceLine" id="cb75-2" data-line-number="2">acc.vec&lt;-<span class="kw">numeric</span>(<span class="kw">length</span>(nd.vec))</a>
<a class="sourceLine" id="cb75-3" data-line-number="3"><span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(nd.vec)) {</a>
<a class="sourceLine" id="cb75-4" data-line-number="4">  cmod&lt;-<span class="kw">textmodel_lsa</span>(combine_corpus.dfm,<span class="dt">nd=</span>nd.vec[j])</a>
<a class="sourceLine" id="cb75-5" data-line-number="5">  df&lt;-<span class="kw">data.frame</span>(<span class="dt">class=</span>y,<span class="dt">x=</span>cmod<span class="op">$</span>docs)</a>
<a class="sourceLine" id="cb75-6" data-line-number="6">  df.tr&lt;-df[index.tr,]</a>
<a class="sourceLine" id="cb75-7" data-line-number="7">  df.te&lt;-df[<span class="op">-</span>index.tr,]</a>
<a class="sourceLine" id="cb75-8" data-line-number="8">  </a>
<a class="sourceLine" id="cb75-9" data-line-number="9">  combine.fit&lt;-<span class="kw">ranger</span>(class<span class="op">~</span>.,</a>
<a class="sourceLine" id="cb75-10" data-line-number="10">                    <span class="dt">data =</span> df.tr)</a>
<a class="sourceLine" id="cb75-11" data-line-number="11">pred.te&lt;-<span class="kw">predict</span>(combine.fit,df.te)</a>
<a class="sourceLine" id="cb75-12" data-line-number="12">acc.vec[j]&lt;-<span class="kw">confusionMatrix</span>(<span class="dt">data=</span>pred.te<span class="op">$</span>predictions,<span class="dt">reference =</span> df.te<span class="op">$</span>class)<span class="op">$</span>overall[<span class="dv">1</span>]</a>
<a class="sourceLine" id="cb75-13" data-line-number="13">  </a>
<a class="sourceLine" id="cb75-14" data-line-number="14">}</a>
<a class="sourceLine" id="cb75-15" data-line-number="15">acc.vec</a>
<a class="sourceLine" id="cb75-16" data-line-number="16"><span class="co">#&gt; [1] 0.671 0.651 0.699 0.726 0.747 0.651 0.651</span></a>
<a class="sourceLine" id="cb75-17" data-line-number="17"></a>
<a class="sourceLine" id="cb75-18" data-line-number="18"><span class="kw">plot</span>(acc.vec<span class="op">~</span>nd.vec,<span class="dt">type=</span><span class="st">&quot;b&quot;</span>)</a></code></pre></div>
<p><img src="Text-Mining_files/figure-html/unnamed-chunk-75-1.png" width="70%" style="display: block; margin: auto;" />
We can see that 100 is the best choice among the ones we tried.</p>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb76-1" data-line-number="1"></a>
<a class="sourceLine" id="cb76-2" data-line-number="2">combine_corpus.dfm &lt;-<span class="st"> </span><span class="kw">dfm</span>(combine_corpus)</a>
<a class="sourceLine" id="cb76-3" data-line-number="3">cmod&lt;-<span class="kw">textmodel_lsa</span>(combine_corpus.dfm,<span class="dt">nd=</span><span class="dv">100</span>)</a>
<a class="sourceLine" id="cb76-4" data-line-number="4"></a>
<a class="sourceLine" id="cb76-5" data-line-number="5">df&lt;-<span class="kw">data.frame</span>(<span class="dt">class=</span>y, <span class="dt">x=</span>cmod<span class="op">$</span>docs)</a>
<a class="sourceLine" id="cb76-6" data-line-number="6">index.tr&lt;-<span class="kw">sample</span>(<span class="dt">size =</span> <span class="kw">round</span>(<span class="fl">0.8</span><span class="op">*</span><span class="kw">length</span>(y)),<span class="dt">x=</span><span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(y)),<span class="dt">replace =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb76-7" data-line-number="7"></a>
<a class="sourceLine" id="cb76-8" data-line-number="8">df.tr&lt;-df[index.tr,]</a>
<a class="sourceLine" id="cb76-9" data-line-number="9">df.te&lt;-df[<span class="op">-</span>index.tr,]</a>
<a class="sourceLine" id="cb76-10" data-line-number="10"></a>
<a class="sourceLine" id="cb76-11" data-line-number="11"></a>
<a class="sourceLine" id="cb76-12" data-line-number="12">combine.fit&lt;-<span class="kw">ranger</span>(class<span class="op">~</span>.,</a>
<a class="sourceLine" id="cb76-13" data-line-number="13">                    <span class="dt">data =</span> df.tr)</a>
<a class="sourceLine" id="cb76-14" data-line-number="14">pred.te&lt;-<span class="kw">predict</span>(combine.fit,df.te)</a>
<a class="sourceLine" id="cb76-15" data-line-number="15"></a>
<a class="sourceLine" id="cb76-16" data-line-number="16"><span class="kw">confusionMatrix</span>(<span class="dt">data=</span>pred.te<span class="op">$</span>predictions,<span class="dt">reference =</span> df.te<span class="op">$</span>class)</a>
<a class="sourceLine" id="cb76-17" data-line-number="17"><span class="co">#&gt; Confusion Matrix and Statistics</span></a>
<a class="sourceLine" id="cb76-18" data-line-number="18"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb76-19" data-line-number="19"><span class="co">#&gt;                Reference</span></a>
<a class="sourceLine" id="cb76-20" data-line-number="20"><span class="co">#&gt; Prediction      Boris Johnson Macron</span></a>
<a class="sourceLine" id="cb76-21" data-line-number="21"><span class="co">#&gt;   Boris Johnson            17      3</span></a>
<a class="sourceLine" id="cb76-22" data-line-number="22"><span class="co">#&gt;   Macron                   37     89</span></a>
<a class="sourceLine" id="cb76-23" data-line-number="23"><span class="co">#&gt;                                         </span></a>
<a class="sourceLine" id="cb76-24" data-line-number="24"><span class="co">#&gt;                Accuracy : 0.726         </span></a>
<a class="sourceLine" id="cb76-25" data-line-number="25"><span class="co">#&gt;                  95% CI : (0.646, 0.797)</span></a>
<a class="sourceLine" id="cb76-26" data-line-number="26"><span class="co">#&gt;     No Information Rate : 0.63          </span></a>
<a class="sourceLine" id="cb76-27" data-line-number="27"><span class="co">#&gt;     P-Value [Acc &gt; NIR] : 0.00926       </span></a>
<a class="sourceLine" id="cb76-28" data-line-number="28"><span class="co">#&gt;                                         </span></a>
<a class="sourceLine" id="cb76-29" data-line-number="29"><span class="co">#&gt;                   Kappa : 0.324         </span></a>
<a class="sourceLine" id="cb76-30" data-line-number="30"><span class="co">#&gt;                                         </span></a>
<a class="sourceLine" id="cb76-31" data-line-number="31"><span class="co">#&gt;  Mcnemar&#39;s Test P-Value : 1.81e-07      </span></a>
<a class="sourceLine" id="cb76-32" data-line-number="32"><span class="co">#&gt;                                         </span></a>
<a class="sourceLine" id="cb76-33" data-line-number="33"><span class="co">#&gt;             Sensitivity : 0.315         </span></a>
<a class="sourceLine" id="cb76-34" data-line-number="34"><span class="co">#&gt;             Specificity : 0.967         </span></a>
<a class="sourceLine" id="cb76-35" data-line-number="35"><span class="co">#&gt;          Pos Pred Value : 0.850         </span></a>
<a class="sourceLine" id="cb76-36" data-line-number="36"><span class="co">#&gt;          Neg Pred Value : 0.706         </span></a>
<a class="sourceLine" id="cb76-37" data-line-number="37"><span class="co">#&gt;              Prevalence : 0.370         </span></a>
<a class="sourceLine" id="cb76-38" data-line-number="38"><span class="co">#&gt;          Detection Rate : 0.116         </span></a>
<a class="sourceLine" id="cb76-39" data-line-number="39"><span class="co">#&gt;    Detection Prevalence : 0.137         </span></a>
<a class="sourceLine" id="cb76-40" data-line-number="40"><span class="co">#&gt;       Balanced Accuracy : 0.641         </span></a>
<a class="sourceLine" id="cb76-41" data-line-number="41"><span class="co">#&gt;                                         </span></a>
<a class="sourceLine" id="cb76-42" data-line-number="42"><span class="co">#&gt;        &#39;Positive&#39; Class : Boris Johnson </span></a>
<a class="sourceLine" id="cb76-43" data-line-number="43"><span class="co">#&gt; </span></a></code></pre></div>
=======
<<<<<<< HEAD
<div class="sourceCode" id="cb94"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb94-1" data-line-number="1">nd.vec&lt;-<span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">5</span>,<span class="dv">25</span>,<span class="dv">50</span>,<span class="dv">100</span>,<span class="dv">500</span>,<span class="dv">1000</span>)</a>
<a class="sourceLine" id="cb94-2" data-line-number="2">acc.vec&lt;-<span class="kw">numeric</span>(<span class="kw">length</span>(nd.vec))</a>
<a class="sourceLine" id="cb94-3" data-line-number="3"><span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(nd.vec)) {</a>
<a class="sourceLine" id="cb94-4" data-line-number="4">  cmod&lt;-<span class="kw">textmodel_lsa</span>(combine_corpus.dfm,<span class="dt">nd=</span>nd.vec[j])</a>
<a class="sourceLine" id="cb94-5" data-line-number="5">  df&lt;-<span class="kw">data.frame</span>(<span class="dt">class=</span>y,<span class="dt">x=</span>cmod<span class="op">$</span>docs)</a>
<a class="sourceLine" id="cb94-6" data-line-number="6">  df.tr&lt;-df[index.tr,]</a>
<a class="sourceLine" id="cb94-7" data-line-number="7">  df.te&lt;-df[<span class="op">-</span>index.tr,]</a>
<a class="sourceLine" id="cb94-8" data-line-number="8">  </a>
<a class="sourceLine" id="cb94-9" data-line-number="9">  combine.fit&lt;-<span class="kw">ranger</span>(class<span class="op">~</span>.,</a>
<a class="sourceLine" id="cb94-10" data-line-number="10">                    <span class="dt">data =</span> df.tr)</a>
<a class="sourceLine" id="cb94-11" data-line-number="11">pred.te&lt;-<span class="kw">predict</span>(combine.fit,df.te)</a>
<a class="sourceLine" id="cb94-12" data-line-number="12">acc.vec[j]&lt;-<span class="kw">confusionMatrix</span>(<span class="dt">data=</span>pred.te<span class="op">$</span>predictions,<span class="dt">reference =</span> df.te<span class="op">$</span>class)<span class="op">$</span>overall[<span class="dv">1</span>]</a>
<a class="sourceLine" id="cb94-13" data-line-number="13">  </a>
<a class="sourceLine" id="cb94-14" data-line-number="14">}</a>
<a class="sourceLine" id="cb94-15" data-line-number="15">acc.vec</a>
<a class="sourceLine" id="cb94-16" data-line-number="16"><span class="co">#&gt; [1] 0.702 0.771 0.743 0.789 0.780 0.697 0.688</span></a>
<a class="sourceLine" id="cb94-17" data-line-number="17"></a>
<a class="sourceLine" id="cb94-18" data-line-number="18"><span class="kw">plot</span>(acc.vec<span class="op">~</span>nd.vec,<span class="dt">type=</span><span class="st">&quot;b&quot;</span>)</a></code></pre></div>
<p><img src="Text-Mining_files/figure-html/unnamed-chunk-55-1.png" width="70%" style="display: block; margin: auto;" />
We can see that 100 is the best choice among the ones we tried.</p>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb95-1" data-line-number="1"></a>
<a class="sourceLine" id="cb95-2" data-line-number="2">combine_corpus.dfm &lt;-<span class="st"> </span><span class="kw">dfm</span>(combine_corpus)</a>
<a class="sourceLine" id="cb95-3" data-line-number="3">cmod&lt;-<span class="kw">textmodel_lsa</span>(combine_corpus.dfm,<span class="dt">nd=</span><span class="dv">100</span>)</a>
<a class="sourceLine" id="cb95-4" data-line-number="4"></a>
<a class="sourceLine" id="cb95-5" data-line-number="5">df&lt;-<span class="kw">data.frame</span>(<span class="dt">class=</span>y, <span class="dt">x=</span>cmod<span class="op">$</span>docs)</a>
<a class="sourceLine" id="cb95-6" data-line-number="6">index.tr&lt;-<span class="kw">sample</span>(<span class="dt">size =</span> <span class="kw">round</span>(<span class="fl">0.8</span><span class="op">*</span><span class="kw">length</span>(y)),<span class="dt">x=</span><span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(y)),<span class="dt">replace =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb95-7" data-line-number="7"></a>
<a class="sourceLine" id="cb95-8" data-line-number="8">df.tr&lt;-df[index.tr,]</a>
<a class="sourceLine" id="cb95-9" data-line-number="9">df.te&lt;-df[<span class="op">-</span>index.tr,]</a>
<a class="sourceLine" id="cb95-10" data-line-number="10"></a>
<a class="sourceLine" id="cb95-11" data-line-number="11"></a>
<a class="sourceLine" id="cb95-12" data-line-number="12">combine.fit&lt;-<span class="kw">ranger</span>(class<span class="op">~</span>.,</a>
<a class="sourceLine" id="cb95-13" data-line-number="13">                    <span class="dt">data =</span> df.tr)</a>
<a class="sourceLine" id="cb95-14" data-line-number="14">pred.te&lt;-<span class="kw">predict</span>(combine.fit,df.te)</a>
<a class="sourceLine" id="cb95-15" data-line-number="15"></a>
<a class="sourceLine" id="cb95-16" data-line-number="16"><span class="kw">confusionMatrix</span>(<span class="dt">data=</span>pred.te<span class="op">$</span>predictions,<span class="dt">reference =</span> df.te<span class="op">$</span>class)</a>
<a class="sourceLine" id="cb95-17" data-line-number="17"><span class="co">#&gt; Confusion Matrix and Statistics</span></a>
<a class="sourceLine" id="cb95-18" data-line-number="18"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb95-19" data-line-number="19"><span class="co">#&gt;                Reference</span></a>
<a class="sourceLine" id="cb95-20" data-line-number="20"><span class="co">#&gt; Prediction      Boris Johnson Macron</span></a>
<a class="sourceLine" id="cb95-21" data-line-number="21"><span class="co">#&gt;   Boris Johnson            89      5</span></a>
<a class="sourceLine" id="cb95-22" data-line-number="22"><span class="co">#&gt;   Macron                   31     93</span></a>
<a class="sourceLine" id="cb95-23" data-line-number="23"><span class="co">#&gt;                                         </span></a>
<a class="sourceLine" id="cb95-24" data-line-number="24"><span class="co">#&gt;                Accuracy : 0.835         </span></a>
<a class="sourceLine" id="cb95-25" data-line-number="25"><span class="co">#&gt;                  95% CI : (0.779, 0.882)</span></a>
<a class="sourceLine" id="cb95-26" data-line-number="26"><span class="co">#&gt;     No Information Rate : 0.55          </span></a>
<a class="sourceLine" id="cb95-27" data-line-number="27"><span class="co">#&gt;     P-Value [Acc &gt; NIR] : &lt; 2e-16       </span></a>
<a class="sourceLine" id="cb95-28" data-line-number="28"><span class="co">#&gt;                                         </span></a>
<a class="sourceLine" id="cb95-29" data-line-number="29"><span class="co">#&gt;                   Kappa : 0.674         </span></a>
<a class="sourceLine" id="cb95-30" data-line-number="30"><span class="co">#&gt;                                         </span></a>
<a class="sourceLine" id="cb95-31" data-line-number="31"><span class="co">#&gt;  Mcnemar&#39;s Test P-Value : 3.09e-05      </span></a>
<a class="sourceLine" id="cb95-32" data-line-number="32"><span class="co">#&gt;                                         </span></a>
<a class="sourceLine" id="cb95-33" data-line-number="33"><span class="co">#&gt;             Sensitivity : 0.742         </span></a>
<a class="sourceLine" id="cb95-34" data-line-number="34"><span class="co">#&gt;             Specificity : 0.949         </span></a>
<a class="sourceLine" id="cb95-35" data-line-number="35"><span class="co">#&gt;          Pos Pred Value : 0.947         </span></a>
<a class="sourceLine" id="cb95-36" data-line-number="36"><span class="co">#&gt;          Neg Pred Value : 0.750         </span></a>
<a class="sourceLine" id="cb95-37" data-line-number="37"><span class="co">#&gt;              Prevalence : 0.550         </span></a>
<a class="sourceLine" id="cb95-38" data-line-number="38"><span class="co">#&gt;          Detection Rate : 0.408         </span></a>
<a class="sourceLine" id="cb95-39" data-line-number="39"><span class="co">#&gt;    Detection Prevalence : 0.431         </span></a>
<a class="sourceLine" id="cb95-40" data-line-number="40"><span class="co">#&gt;       Balanced Accuracy : 0.845         </span></a>
<a class="sourceLine" id="cb95-41" data-line-number="41"><span class="co">#&gt;                                         </span></a>
<a class="sourceLine" id="cb95-42" data-line-number="42"><span class="co">#&gt;        &#39;Positive&#39; Class : Boris Johnson </span></a>
<a class="sourceLine" id="cb95-43" data-line-number="43"><span class="co">#&gt; </span></a></code></pre></div>
=======
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">nd.vec&lt;-<span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">5</span>,<span class="dv">25</span>,<span class="dv">50</span>,<span class="dv">100</span>,<span class="dv">500</span>,<span class="dv">1000</span>)
acc.vec&lt;-<span class="kw">numeric</span>(<span class="kw">length</span>(nd.vec))
for (j in <span class="dv">1</span>:<span class="kw">length</span>(nd.vec)) {
  cmod&lt;-<span class="kw">textmodel_lsa</span>(combine_corpus.dfm,<span class="dt">nd=</span>nd.vec[j])
  df&lt;-<span class="kw">data.frame</span>(<span class="dt">class=</span>y,<span class="dt">x=</span>cmod$docs)
  df.tr&lt;-df[index.tr,]
  df.te&lt;-df[-index.tr,]
  
  combine.fit&lt;-<span class="kw">ranger</span>(class~.,
                    <span class="dt">data =</span> df.tr)
pred.te&lt;-<span class="kw">predict</span>(combine.fit,df.te)
acc.vec[j]&lt;-<span class="kw">confusionMatrix</span>(<span class="dt">data=</span>pred.te$predictions,<span class="dt">reference =</span> df.te$class)$overall[<span class="dv">1</span>]
  
}
acc.vec
<span class="co">#&gt; [1] 0.740 0.721 0.766 0.747 0.766 0.740 0.747</span>

<span class="kw">plot</span>(acc.vec~nd.vec,<span class="dt">type=</span><span class="st">&quot;b&quot;</span>)</code></pre></div>
<p><img src="Text-Mining_files/figure-html/unnamed-chunk-73-1.png" width="70%" style="display: block; margin: auto;" /> We can see that 100 is the best choice among the ones we tried.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">
combine_corpus.dfm &lt;-<span class="st"> </span><span class="kw">dfm</span>(combine_corpus)
cmod&lt;-<span class="kw">textmodel_lsa</span>(combine_corpus.dfm,<span class="dt">nd=</span><span class="dv">100</span>)

df&lt;-<span class="kw">data.frame</span>(<span class="dt">class=</span>y, <span class="dt">x=</span>cmod$docs)
index.tr&lt;-<span class="kw">sample</span>(<span class="dt">size =</span> <span class="kw">round</span>(<span class="fl">0.8</span>*<span class="kw">length</span>(y)),<span class="dt">x=</span><span class="kw">c</span>(<span class="dv">1</span>:<span class="kw">length</span>(y)),<span class="dt">replace =</span> <span class="ot">FALSE</span>)

df.tr&lt;-df[index.tr,]
df.te&lt;-df[-index.tr,]


combine.fit&lt;-<span class="kw">ranger</span>(class~.,
                    <span class="dt">data =</span> df.tr)
pred.te&lt;-<span class="kw">predict</span>(combine.fit,df.te)

<span class="kw">confusionMatrix</span>(<span class="dt">data=</span>pred.te$predictions,<span class="dt">reference =</span> df.te$class)
<span class="co">#&gt; Confusion Matrix and Statistics</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;                Reference</span>
<span class="co">#&gt; Prediction      Boris Johnson Macron</span>
<span class="co">#&gt;   Boris Johnson            37      4</span>
<span class="co">#&gt;   Macron                   25     88</span>
<span class="co">#&gt;                                        </span>
<span class="co">#&gt;                Accuracy : 0.812        </span>
<span class="co">#&gt;                  95% CI : (0.741, 0.87)</span>
<span class="co">#&gt;     No Information Rate : 0.597        </span>
<span class="co">#&gt;     P-Value [Acc &gt; NIR] : 1.05e-08     </span>
<span class="co">#&gt;                                        </span>
<span class="co">#&gt;                   Kappa : 0.586        </span>
<span class="co">#&gt;                                        </span>
<span class="co">#&gt;  Mcnemar&#39;s Test P-Value : 0.000204     </span>
<span class="co">#&gt;                                        </span>
<span class="co">#&gt;             Sensitivity : 0.597        </span>
<span class="co">#&gt;             Specificity : 0.957        </span>
<span class="co">#&gt;          Pos Pred Value : 0.902        </span>
<span class="co">#&gt;          Neg Pred Value : 0.779        </span>
<span class="co">#&gt;              Prevalence : 0.403        </span>
<span class="co">#&gt;          Detection Rate : 0.240        </span>
<span class="co">#&gt;    Detection Prevalence : 0.266        </span>
<span class="co">#&gt;       Balanced Accuracy : 0.777        </span>
<span class="co">#&gt;                                        </span>
<span class="co">#&gt;        &#39;Positive&#39; Class : Boris Johnson</span>
<span class="co">#&gt; </span></code></pre></div>
>>>>>>> 29935c5794a00d63f04fc627797334b4417963c0
>>>>>>> 38a3e356d3937ca2d4b6bf974a95a42157fd08d1
<p>We clearly improve the accruacy in adding more dimensions</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="word-embedding.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="conclusion.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
